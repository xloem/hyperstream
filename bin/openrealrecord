#!/usr/bin/env node

var openrealrecord = require('..')
var minimist = require('minimist')
var low = require('last-one-wins')
var path = require('path')
var util = require('../lib/util')
var sparsestorage = require('../lib/sparse-storage')

var opts = minimist(process.argv.slice(2))

// TODO: reading from stdin should be modular like timestamping
//       reading from stdout could be too

if (opts.help || process.argv.length === 2) {
  console.log('\nDecentralized secure binary streaming, powered by hyperdb\n')

  console.log('  --storage path            save database to path')
  console.log('  --db key                  database to use')
  console.log('  --quiet                   do not output anything')
  console.log('  --info                    output database info (default when not piping out)')
  console.log('  --sync                    sync with a network peer before doing anything else')
  console.log('  --serve                   connect to the network and communicate until terminated')
  console.log('  --authorize [key]         publish a user\'s stream')
  console.log('  --pipe [key]              publish from stdin and/or write to stdout if key given')
  console.log('  --incache minMB:maxMB     delete cached data down to minMB when exceeds maxMB')
  console.log('  --start offset            rewind stream to offset before output')
  console.log('  --my-name name            set stream name')
  console.log('  --my-owner key            set stream owner')
  console.log('')
  console.log('  --my-messages "timestamp" produce timestamps with this stream')
  console.log('  --timestamp "bcoin-tip"   store blockchain tip hashes from bcoin')
  console.log('  --bcoin-port port         port of bcoin instance')
  console.log('  --bcoin-host host         address of bcoin instance')
  console.log('')

  process.exit(0)
}

var storage
if (opts.storage) {
	storage = function (name) {
		return sparsestorage(path.join(opts.storage, name))
	}
} else {
	storage = require('random-access-memory')
}
var key = opts.db && Buffer.from(opts.db, 'base64')

var orr = openrealrecord(storage, key, {tracedebug: opts.tracedebug})

orr.db.ready(orrDbReady)

var sw = null
var outstream = null

function orrDbReady() {
  
  if (!opts.pipe || opts.pipe === true) {
    if (!opts.quiet)
      opts.info = true
  }
  if (!opts.storage && !opts.db) {
    opts.serve = true
  }
  if (opts.info && !opts.storage) {
    console.log('Generated an in-memory database.')
  }
  
  if (opts.sync || opts.serve) {
    sw = require('hyperdiscovery')(orr.db, {port:3283})
    if (opts.info) {
      console.log('Connecting to hyperdiscovery network.')
    }
    sw.once('error', function(err) {
      // TODO: this quick hack should be replaced with perhaps proper IPC
      // it makes assumptions about the undocumented even ordering inside swarm-discovery
      // and it assumes that if somebody is listening on our port, it is another copy of us
      if (err.syscall === 'listen' && err.code === 'EADDRINUSE') {
        console.log('Port ' + err.port + ' already in use; attempting to connect to it.')
        sw.once('listening', function() {
          sw.addPeer(orr.db.discoveryKey, err)
        })
      } else {
        throw(err)
      }
    })
  }

  orr.ready(orrReady)
}

function orrReady() {

  if (opts.info) {
    console.log('Database: ' + util.keyToID(orr.db.key))
    console.log('User: ' + util.keyToID(orr.db.local.key))

    if (opts.verbose) {
      orr.db.on('remote-update', function(feed, id) { console.log('DB: remote-update ' + feed.key.toString('base64') + ' #' + id) })
      orr.db.on('append', function(feed, id) { console.log('DB: append ' + feed.key.toString('base64') + ' #' + id) })
    }

    if (sw) {
      if (opts.verbose) {
        sw.on('close', function() { console.log('NET: close') })
        sw.on('peer', function(peer) { console.log('NET: peer ' + peer.id) })
        sw.on('drop', function(peer) { console.log('NET: drop ' + peer.id) })
        sw.on('connecting', function(next) { console.log('NET: connecting ' + next.id) })
        sw.on('connection', function(connection, info) { console.log('NET: connection ' + connection.key.toString('base64') + ' (' + info.type +')') })
        sw.on('error', function(err) { console.log('NET: error ' + err) })
        sw.on('listening', function() { console.log('NET: listening') })
      }
    }
  }

  if (opts.sync) {
    orr.db.once('remote-update', setmetadata)
  } else {
    setmetadata()
  }
}

function setmetadata () {

  var metadata = orr.localStream.generateMetadata({}, opts)
  if (!Object.keys(metadata).length) return streamsOut()

  var metadata = orr.localStream.generateMetadata({...orr.localStream.metadata}, opts)

  orr.localStream.setMetadata(metadata, function (err, metadata) {
    if (err) console.error(err)
    streamsOut()
  })
}

function streamsOut () {
  if (!opts.info) return main()

  var streams = orr.getStreams()
  console.log(streams.length + ' Streams:')

  var idx = 0
  var stream
  var streamErr
  var streamName
  var streamLen
  var startingBadCheckpoints
  var numValidatedStart
  var endingBadCheckpoints
  var numValidatedEnd

  streamOut()
 
  function streamOut() {
    if (opts.tracedebug) console.log('streamOut')
    orr.getStream(streams[idx], gotStream)
  }

  function gotStream (err, s) {
    if (opts.tracedebug) console.log('gotStream', err)
    stream = s
    if (err) {
      streamErr = err
      streamName = streams[idx]
      streamLen = 0
      return summarize()
    }
    streamErr = null
    streamName = stream.metadata.name
    streamLen = stream.feed.byteLength
    stream.validateMetadata(stream.metadata, validatedMetadata)
  }

  function validatedMetadata (err) {
    if (opts.tracedebug) console.log('validatedMetadata', err)
    if (err) streamErr = err

    startingBadCheckpoints = 0
    numValidatedStart = 0
    endingBadCheckpoints = 0
    numValidatedEnd = 0

    stream.findValidCheckpoint(null, firstGoodCheckpoint, startingBadCheckpoint)

    function startingBadCheckpoint () {
      if (opts.tracedebug) console.log('startingBadCheckpoint')
      ++startingBadCheckpoints
    }
    function firstGoodCheckpoint (err, checkpoint) {
      if (opts.tracedebug) console.log('firstGoodCheckpoint', err)
      if (err) {
        streamErr = err
      }
      if (!checkpoint) {
        summarize()
      } else {
        numValidatedStart = checkpoint.byteLength
        stream.findValidCheckpoint({'reverse': true}, lastGoodCheckpoint, endingBadCheckpoint)
      }
    }
    function endingBadCheckpoint () {
      if (opts.tracedebug) console.log('endingBadCheckpoint')
      ++endingBadCheckpoints
    }
    function lastGoodCheckpoint (err, checkpoint) {
      if (opts.tracedebug) console.log('lastGoodCheckpoint', err)
      if (err) streamErr = err
      else if (checkpoint) numValidatedEnd = checkpoint.byteLength
      summarize()
    }
  }

  function summarize() {
    var str = '  '
    str += streamName
    if (!streamErr) str += ' (' + streams[idx] + ')'
    else str += ' { ERR ' + streamErr.message + ' }'
    if (startingBadCheckpoints) str += ' { WARN genesis -> ' + startingBadCheckpoints + ' bad }'
    if (endingBadCheckpoints) str += ' { WARN ' + endingBadCheckpoints + ' <- now }'
    str += ' ' + numValidatedEnd + 'B'
    if (streamLen > numValidatedEnd) {
      var remaining = streamLen - numValidatedEnd
      str += ' (+' + remaining + 'B unhashed)'
    }
    console.log(str)
    nextloop()
  }

  function nextloop() {
    ++idx
    if (idx < streams.length) return streamOut()
    else return main()
  }
}

function main (err) {
  if (err) console.error(err)
  try {
    if (opts.authorize) {
      var authorizee = opts.authorize
      opts.authorize = null
      return orr.db.authorize(Buffer.from(authorizee, 'base64'), main)
    }
    if (opts.pipe) {
      var writeStream = orr.createWriteStream()
      writeStream.on('error', console.error)
      process.stdin.pipe(writeStream)
      process.stdin.on('end', finish)
      if (opts.incache) {
        incachemarkbytes = 0
        incachemarkblocks = 0
	var incache = opts.incache.split(':')
        incacheminsize = incache[0] * 1024 * 1024
	incachemaxsize = incache[1] * 1024 * 1024
        orr.localStream.feed.on('append', onappendshrinkincache)
      }
      if (opts.pipe !== true) {
        pipeout(opts.pipe, finish)
      }
    }
    if (opts.serve || opts.start) {
      orr.localStream.start(()=>{}, finish)
    }
    if (sw && !opts.serve && !opts.pipe && !opts.start) {
      finish()
    }
  } catch(e) {
    finish(e)
  }
}

// only store the last cache bytes if enabled
var incachemarkbytes
var incachemarkblocks
var incachesize
function onappendshrinkincache() {
  var feed = orr.localStream.feed
  var len = feed.byteLength
  if (len - incachemarkbytes >= incachemaxsize) {
    feed.removeListener('append', onappendshrinkincache)
    var destbytes = len - incacheminsize
    var destblocks
    feed.seek(destbytes, function (err, index, offset) {
      if (err) return console.log('Seeking to clear cache ERROR: ' + err)
      if (index >= feed.length - 1) {
        destblocks = feed.length - 1
        destbytes -= offset
        shrink()
      } else {
        destblocks = index
        feed.get(destblocks, { wait: false, valueEncoding: 'binary' }, function (err, data) {
          if (!err) destbytes += data.length - offset
          shrink()
        })
      }
    })
  }

  function shrink() {
    feed.clear(incachemarkblocks, destblocks, shrank)
  }
  function shrank() {
    incachemarkblocks = destblocks
    incachemarkbytes = destbytes
    feed.on('append', onappendshrinkincache)
  }
}

function pipeout (key, cb) {
  outstream = orr.getStream(key, function (err) {
    if (err) return finish(err)
    var end = 0
    var nextend = null
    var start = 0
    var keepStreaming = false

    outstream.findValidCheckpoint({'reverse': true}, function (err, checkpoint) {
      if (checkpoint) end = checkpoint.byteLength
      startStreaming()
    }, console.error)

    const BLOCKSIZE = 1024 * 1024
    var writeout = low(function(length, cb2) {
      var remaining = 0
      if (length > BLOCKSIZE) {
        remaining = length - BLOCKSIZE
        length = BLOCKSIZE
      }
      outstream.read(start, length, {}, function (err, data) {
        if (err) return cb(err)
        process.stdout.write(data)
        start += data.length
        cb2()
        if (remaining) writeout(remaining)
      })
    })

    function startStreaming() {
      keepStreaming = true
      if (opts.start === undefined)
        opts.start = end
      start = opts.start
      if (start > end) {
        return cb(new Error('start offset is past end of verified stream'))
      }
      if (nextend) {
        end = nextend
        nextend = null
      }
      if (end != start) writeout(end - start)
    }

    outstream.listen()
    outstream.on('error', function (err) {
      console.error(err)
    })
    outstream.on('checkpoint', function (checkpoint) {
      if (checkpoint.byteLength <= end) return console.error('checkpoint fails to advance')
      outstream.verify(checkpoint, function(err) {
        if (err) return console.error(err)
        if (!keepStreaming) {
          console.error('Warning: found new valid data before finding validated previous tail')
          nextend = checkpoint.byteLength
        } else {
          end = checkpoint.byteLength
          if (end != start) writeout(end - start)
        }
      })
    })
  })
}

function finish (err) {
  if (err) console.error(err)
  if (outstream && outstream.listening()) outstream.ignore()
  if (sw) sw.close()
}




